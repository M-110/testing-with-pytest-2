{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Writing_Test_Functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUu1eiAU2DDmmgf5CFtFsU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-110/testing-with-pytest-2/blob/main/02_Writing_Test_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "h_buo5O4UTZ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "777QTjrh0dKD",
        "outputId": "b3732bf6-eb6b-41c5-e422-1105745e0ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 297 kB 5.1 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pytest --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://media.pragprog.com/titles/bopytest2/code/bopytest2-code.zip -q\n",
        "!unzip -q bopytest2-code.zip"
      ],
      "metadata": {
        "id": "RiXYxN8c4FtN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd code/cards_proj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGw9gChs0gsy",
        "outputId": "72b3e95e-b75c-4afa-bdfd-d45de0509223"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/code/cards_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tinydb -q\n",
        "!pip install typer -q\n",
        "!pip install rich -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTSR5AsATyP0",
        "outputId": "d90cdee7-32d7-43f6-cbae-e6fddac41d80"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 61 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 71 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 232 kB 5.1 MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |██████▍                         | 10 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30 kB 42.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 40 kB 47.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51 kB 6.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify pythonpath from pytest.ini"
      ],
      "metadata": {
        "id": "dgXpFq7LUyvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pytest.ini\n",
        "[pytest]\n",
        "pythonpath = src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TewqlTnZUMxV",
        "outputId": "7991638c-3bb0-4d6c-b57f-1531307a8573"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pytest.ini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir tests"
      ],
      "metadata": {
        "id": "h4xXl72B7VE1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic tests"
      ],
      "metadata": {
        "id": "aJ0CzlZ2UYSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests/test_card.py\n",
        "\"\"\"Test card data class\"\"\"\n",
        "from cards import Card\n",
        "\n",
        "\n",
        "def test_field_access():\n",
        "    card = Card(\"something\", \"brian\", \"todo\", 123)\n",
        "    assert card.summary == \"something\"\n",
        "    assert card.owner == \"brian\"\n",
        "    assert card.state == \"todo\"\n",
        "    assert card.id == 123\n",
        "\n",
        "\n",
        "def test_defaults():\n",
        "    card = Card()\n",
        "    assert card.summary is None\n",
        "    assert card.owner is None\n",
        "    assert card.state == \"todo\"\n",
        "    assert card.id is None\n",
        "\n",
        "\n",
        "def test_equality():\n",
        "    card1 = Card(\"something\", \"brian\", \"todo\", 123)\n",
        "    card2 = Card(\"something\", \"brian\", \"todo\", 123)\n",
        "    assert card1 == card2\n",
        "\n",
        "\n",
        "def test_equality_with_different_ids():\n",
        "    card1 = Card(\"something\", \"brian\", \"todo\", 123)\n",
        "    card2 = Card(\"something\", \"brian\", \"todo\", 1234)\n",
        "    assert card1 == card2\n",
        "\n",
        "\n",
        "def test_from_dict():\n",
        "    card_dict = dict(summary=\"something\",\n",
        "                     owner=\"brian\",\n",
        "                     state=\"todo\",\n",
        "                     id=123)\n",
        "    card1 = Card(\"something\", \"brian\", \"todo\", 123)\n",
        "    card2 = Card.from_dict(card_dict)\n",
        "    assert card1 == card2\n",
        "\n",
        "\n",
        "def test_to_dict():\n",
        "    card = Card(\"something\", \"brian\", \"todo\", 123)\n",
        "    expected_card_dict = dict(summary=\"something\",\n",
        "                              owner=\"brian\",\n",
        "                              state=\"todo\",\n",
        "                              id=123)\n",
        "    actual_card_dict = card.to_dict()\n",
        "    assert expected_card_dict == actual_card_dict\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7HFFNot7YQz",
        "outputId": "d4d9b0a9-5b77-4044-cc72-2e1ee5a3de80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tests/test_card.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pytest -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUm5Gx1I7at9",
        "outputId": "a28c9ba1-beca-4e68-ec32-106769786cff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/code/cards_proj, configfile: pytest.ini\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 6 items                                                              \u001b[0m\n",
            "\n",
            "tests/test_card.py::test_field_access \u001b[32mPASSED\u001b[0m\u001b[32m                             [ 16%]\u001b[0m\n",
            "tests/test_card.py::test_defaults \u001b[32mPASSED\u001b[0m\u001b[32m                                 [ 33%]\u001b[0m\n",
            "tests/test_card.py::test_equality \u001b[32mPASSED\u001b[0m\u001b[32m                                 [ 50%]\u001b[0m\n",
            "tests/test_card.py::test_equality_with_different_ids \u001b[32mPASSED\u001b[0m\u001b[32m              [ 66%]\u001b[0m\n",
            "tests/test_card.py::test_from_dict \u001b[32mPASSED\u001b[0m\u001b[32m                                [ 83%]\u001b[0m\n",
            "tests/test_card.py::test_to_dict \u001b[32mPASSED\u001b[0m\u001b[32m                                  [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m6 passed\u001b[0m\u001b[32m in 0.08s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytest.fail()\n",
        "\n",
        "used as an assertion helper"
      ],
      "metadata": {
        "id": "Y8YQDcEEUcS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests/test_fail.py\n",
        "import pytest\n",
        "\n",
        "\n",
        "def test_pytest_fail():\n",
        "  pytest.fail(\"Oh no!\")"
      ],
      "metadata": {
        "id": "A86lueF07d5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f321d40f-46ff-4085-cf33-2672df447e75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tests/test_fail.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvvkVTnEU_v3",
        "outputId": "28249299-d517-4a7f-caea-f5183e49b338"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0\n",
            "rootdir: /content/code/cards_proj, configfile: pytest.ini\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 7 items                                                              \u001b[0m\n",
            "\n",
            "tests/test_card.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                [ 85%]\u001b[0m\n",
            "tests/test_fail.py \u001b[31mF\u001b[0m\u001b[31m                                                     [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_______________________________ test_pytest_fail _______________________________\u001b[0m\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_pytest_fail\u001b[39;49;00m():\n",
            ">     pytest.fail(\u001b[33m\"\u001b[39;49;00m\u001b[33mOh no!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
            "\u001b[1m\u001b[31mE     Failed: Oh no!\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_fail.py\u001b[0m:5: Failed\n",
            "=========================== short test summary info ============================\n",
            "FAILED tests/test_fail.py::test_pytest_fail - Failed: Oh no!\n",
            "\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m6 passed\u001b[0m\u001b[31m in 0.16s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests/test_fail_2.py\n",
        "import pytest\n",
        "from cards import Card\n",
        "\n",
        "\n",
        "def assert_identical(c1, c2):\n",
        "  __tracebackhide__ = True\n",
        "  assert c1 == c2\n",
        "  if c1.id != c2.id:\n",
        "    pytest.fail(f\"id's don't match. {c1.id} != {c2.id}\")\n",
        "\n",
        "\n",
        "def test_identical():\n",
        "  c1 = Card(\"foo\", id=123)\n",
        "  c2 = Card(\"foo\", id=124)\n",
        "  assert_identical(c1, c2)\n",
        "\n",
        "def test_identical_2():\n",
        "  c1 = Card(\"foo\", id=123)\n",
        "  c2 = Card(\"foo\", id=124)\n",
        "  assert c1.id == c2.id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ai13dR6VBZC",
        "outputId": "73b7802b-2263-43cb-9827-b9b163747f83"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tests/test_fail_2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ0iNPrgV1WF",
        "outputId": "32590730-a032-4939-d05d-a6e813ce22a8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/code/cards_proj, configfile: pytest.ini\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 9 items                                                              \u001b[0m\n",
            "\n",
            "test_fail_2.py::test_identical \u001b[31mFAILED\u001b[0m\u001b[31m                                    [ 11%]\u001b[0m\n",
            "test_fail_2.py::test_identical_2 \u001b[31mFAILED\u001b[0m\u001b[31m                                  [ 22%]\u001b[0m\n",
            "tests/test_card.py::test_field_access \u001b[32mPASSED\u001b[0m\u001b[31m                             [ 33%]\u001b[0m\n",
            "tests/test_card.py::test_defaults \u001b[32mPASSED\u001b[0m\u001b[31m                                 [ 44%]\u001b[0m\n",
            "tests/test_card.py::test_equality \u001b[32mPASSED\u001b[0m\u001b[31m                                 [ 55%]\u001b[0m\n",
            "tests/test_card.py::test_equality_with_different_ids \u001b[32mPASSED\u001b[0m\u001b[31m              [ 66%]\u001b[0m\n",
            "tests/test_card.py::test_from_dict \u001b[32mPASSED\u001b[0m\u001b[31m                                [ 77%]\u001b[0m\n",
            "tests/test_card.py::test_to_dict \u001b[32mPASSED\u001b[0m\u001b[31m                                  [ 88%]\u001b[0m\n",
            "tests/test_fail.py::test_pytest_fail \u001b[31mFAILED\u001b[0m\u001b[31m                              [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m________________________________ test_identical ________________________________\u001b[0m\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_identical\u001b[39;49;00m():\n",
            "      c1 = Card(\u001b[33m\"\u001b[39;49;00m\u001b[33mfoo\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[96mid\u001b[39;49;00m=\u001b[94m123\u001b[39;49;00m)\n",
            "      c2 = Card(\u001b[33m\"\u001b[39;49;00m\u001b[33mfoo\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[96mid\u001b[39;49;00m=\u001b[94m124\u001b[39;49;00m)\n",
            ">     assert_identical(c1, c2)\n",
            "\u001b[1m\u001b[31mE     Failed: id's don't match. 123 != 124\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_fail_2.py\u001b[0m:15: Failed\n",
            "\u001b[31m\u001b[1m_______________________________ test_identical_2 _______________________________\u001b[0m\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_identical_2\u001b[39;49;00m():\n",
            "      c1 = Card(\u001b[33m\"\u001b[39;49;00m\u001b[33mfoo\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[96mid\u001b[39;49;00m=\u001b[94m123\u001b[39;49;00m)\n",
            "      c2 = Card(\u001b[33m\"\u001b[39;49;00m\u001b[33mfoo\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[96mid\u001b[39;49;00m=\u001b[94m124\u001b[39;49;00m)\n",
            ">     \u001b[94massert\u001b[39;49;00m c1.id == c2.id\n",
            "\u001b[1m\u001b[31mE     AssertionError: assert 123 == 124\u001b[0m\n",
            "\u001b[1m\u001b[31mE      +  where 123 = Card(summary='foo', owner=None, state='todo', id=123).id\u001b[0m\n",
            "\u001b[1m\u001b[31mE      +  and   124 = Card(summary='foo', owner=None, state='todo', id=124).id\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_fail_2.py\u001b[0m:20: AssertionError\n",
            "\u001b[31m\u001b[1m_______________________________ test_pytest_fail _______________________________\u001b[0m\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_pytest_fail\u001b[39;49;00m():\n",
            ">     pytest.fail(\u001b[33m\"\u001b[39;49;00m\u001b[33mOh no!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
            "\u001b[1m\u001b[31mE     Failed: Oh no!\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtests/test_fail.py\u001b[0m:5: Failed\n",
            "=========================== short test summary info ============================\n",
            "FAILED test_fail_2.py::test_identical - Failed: id's don't match. 123 != 124\n",
            "FAILED test_fail_2.py::test_identical_2 - AssertionError: assert 123 == 124\n",
            "FAILED tests/test_fail.py::test_pytest_fail - Failed: Oh no!\n",
            "\u001b[31m========================= \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m6 passed\u001b[0m\u001b[31m in 0.16s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expected exceptions"
      ],
      "metadata": {
        "id": "QeC2oH07X5AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests/test_exceptions.py\n",
        "import pytest\n",
        "\n",
        "import cards\n",
        "\n",
        "import pytest\n",
        "import cards\n",
        "\n",
        "\n",
        "def test_no_path_raises():\n",
        "    with pytest.raises(TypeError):\n",
        "        cards.CardsDB()\n",
        "\n",
        "\n",
        "def test_raises_with_info():\n",
        "    match_re = r\"missing 1 .* positional argument\"\n",
        "    with pytest.raises(TypeError, match=match_re):\n",
        "        cards.CardsDB()\n",
        "\n",
        "\n",
        "def test_raises_with_info_alt():\n",
        "    with pytest.raises(TypeError) as info:\n",
        "        cards.CardsDB()\n",
        "    expected = \"missing 1 required positional argument\"\n",
        "    assert expected in str(info.value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKoeHNHqV3WQ",
        "outputId": "a049d429-0416-4b4a-d8f4-b5c5449a42a4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tests/test_exceptions.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest tests/test_exceptions.py -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tlWvjVyYjid",
        "outputId": "10e6b4cf-c0b0-4ba6-ee83-29dbb4430a05"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/code/cards_proj, configfile: pytest.ini\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 3 items                                                              \u001b[0m\n",
            "\n",
            "tests/test_exceptions.py::test_no_path_raises \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 33%]\u001b[0m\n",
            "tests/test_exceptions.py::test_raises_with_info \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 66%]\u001b[0m\n",
            "tests/test_exceptions.py::test_raises_with_info_alt \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.06s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structuring Test Functions\n",
        "\n",
        "**Arrange-Act-Assert**\n",
        "\n",
        "or\n",
        "\n",
        "**Given-When-Then**\n",
        "\n",
        "1. Get ready to do something\n",
        "2. Do something\n",
        "3. Check that it worked\n",
        "\n",
        "**Do NOT** interleave multiple assert patterns in a test function\n"
      ],
      "metadata": {
        "id": "MzKgFCVlZr8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests/test_gwt.py\n",
        "from cards import Card\n",
        "\n",
        "\n",
        "def test_to_dict():\n",
        "  # Given a card with known contents and a dictionar with matching contents\n",
        "  card = Card(\"something\", \"brian\", \"todo\", 123)\n",
        "  expected_card_dict = dict(summary=\"something\",\n",
        "                            owner=\"brian\",\n",
        "                            state=\"todo\",\n",
        "                            id=123)\n",
        "  \n",
        "  # When to_dict is called on the card\n",
        "  actual_card_dict = card.to_dict()\n",
        "\n",
        "  # Then the resulting dictionary will match the original contents\n",
        "  assert expected_card_dict == actual_card_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an4ncrw4b-k5",
        "outputId": "ad21f966-0c36-43ee-8058-a71b6c7ee18c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tests/test_gwt.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grouping Tests with classes"
      ],
      "metadata": {
        "id": "pAqnQWcadg7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tests/test_classes.py\n",
        "from cards import Card\n",
        "\n",
        "\n",
        "class TestEquality:\n",
        "  def test_equality(self):\n",
        "    c1 = Card(\"a\", \"b\", \"c\", 123)\n",
        "    c2 = Card(\"a\", \"b\", \"c\", 123)\n",
        "    assert c1 == c2\n",
        "\n",
        "  def test_equality_with_different_ids(self):\n",
        "    c1 = Card(\"a\", \"b\", \"c\", 123)\n",
        "    c2 = Card(\"a\", \"b\", \"c\", 124)\n",
        "    assert c1 == c2\n",
        "\n",
        "  def test_inequality(self):\n",
        "    c1 = Card(\"a\", \"b\", \"c\", 123)\n",
        "    c2 = Card(\"a\", \"b\", \"d\", 123)\n",
        "    assert c1 != c2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGOBbFYhYlZ4",
        "outputId": "9e3b7628-1c91-4e34-801f-2a90fb6de7f3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tests/test_classes.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest tests/test_classes.py -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Gq0dxDeVSL",
        "outputId": "cac67c9f-e7db-460b-d189-ef60f4f7ffde"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content/code/cards_proj, configfile: pytest.ini\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 3 items                                                              \u001b[0m\n",
            "\n",
            "tests/test_classes.py::TestEquality::test_equality \u001b[32mPASSED\u001b[0m\u001b[32m                [ 33%]\u001b[0m\n",
            "tests/test_classes.py::TestEquality::test_equality_with_different_ids \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
            "tests/test_classes.py::TestEquality::test_inequality \u001b[32mPASSED\u001b[0m\u001b[32m              [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.07s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running subset of tests\n",
        "\n",
        "Subset | Syntax\n",
        "--- | ---\n",
        "Single test method | pytest path/test_module.py::TestClass::test_method\n",
        "All tests in a class | pytest path/test_module.py::TestClass\n",
        "Single test function | pytest path/test_module.py::test_function\n",
        "All tests in a module | pytest path/test_module.py\n",
        "All tests in a directory | pytest path\n",
        "Tests matching a name pattern | pytest -k pattern\n",
        "Tests by marker | Covered in Chapter 6, ​Markers​."
      ],
      "metadata": {
        "id": "KGh55pG8fFKz"
      }
    }
  ]
}