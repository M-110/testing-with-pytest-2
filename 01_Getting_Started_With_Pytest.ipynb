{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Getting_Started_With_Pytest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcqkPCkDjdVdTCQpd7NzIs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-110/testing-with-pytest-2/blob/main/01_Getting_Started_With_Pytest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2Da87SuvXWb",
        "outputId": "89f933e5-0402-439b-828e-9d2fecf0c3eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Collecting pytest\n",
            "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
            "\u001b[K     |████████████████████████████████| 297 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest) (4.11.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest) (21.4.0)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest) (1.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest) (21.3)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytest) (3.0.9)\n",
            "Installing collected packages: pluggy, pytest\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed pluggy-1.0.0 pytest-7.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytest --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple tests"
      ],
      "metadata": {
        "id": "LVjaN_Q2vwIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_one.py\n",
        "def test_passing():\n",
        "  assert (1, 2, 3) == (1, 2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH9NVCBTv0Gy",
        "outputId": "a42feaa7-75ff-4234-d0a3-05f705de0fed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_one.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest test_one.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tShPSc88wElQ",
        "outputId": "9de15b6a-e39b-4dcd-cfd8-46ecf85cc29a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0\n",
            "rootdir: /content\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_one.py \u001b[32m.\u001b[0m\u001b[32m                                                            [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -v for verbose"
      ],
      "metadata": {
        "id": "2_SaOH-awKvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest -v test_one.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LguKlTI6wGxX",
        "outputId": "8430154a-b1e3-4d91-c16f-a37ec8f216a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_one.py::test_passing \u001b[32mPASSED\u001b[0m\u001b[32m                                         [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_two.py\n",
        "def test_failing():\n",
        "  assert (1, 2, 3) == (3, 2, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ_3lSTtwNKA",
        "outputId": "ef74ad11-af0d-48b0-8be4-a10c99dd031d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_two.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest -v test_two.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jybPg0Ckwrf2",
        "outputId": "f0f398e4-4da1-494c-c6fc-32e23fb70d6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_two.py::test_failing \u001b[31mFAILED\u001b[0m\u001b[31m                                         [100%]\u001b[0m\n",
            "\n",
            "=================================== FAILURES ===================================\n",
            "\u001b[31m\u001b[1m_________________________________ test_failing _________________________________\u001b[0m\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_failing\u001b[39;49;00m():\n",
            ">     \u001b[94massert\u001b[39;49;00m (\u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m) == (\u001b[94m3\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m)\n",
            "\u001b[1m\u001b[31mE     assert (1, 2, 3) == (3, 2, 1)\u001b[0m\n",
            "\u001b[1m\u001b[31mE       At index 0 diff: 1 != 3\u001b[0m\n",
            "\u001b[1m\u001b[31mE       Full diff:\u001b[0m\n",
            "\u001b[1m\u001b[31mE       - (3, 2, 1)\u001b[0m\n",
            "\u001b[1m\u001b[31mE       ?  ^     ^\u001b[0m\n",
            "\u001b[1m\u001b[31mE       + (1, 2, 3)\u001b[0m\n",
            "\u001b[1m\u001b[31mE       ?  ^     ^\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mtest_two.py\u001b[0m:2: AssertionError\n",
            "=========================== short test summary info ============================\n",
            "FAILED test_two.py::test_failing - assert (1, 2, 3) == (3, 2, 1)\n",
            "\u001b[31m============================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.09s\u001b[0m\u001b[31m ===============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hide traceback --tb=no"
      ],
      "metadata": {
        "id": "WocaNSNhw0Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest -v test_two.py --tb=no"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn2xSekVwsbP",
        "outputId": "1ae156a4-8447-49ae-8fc8-5754ca10c8bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_two.py::test_failing \u001b[31mFAILED\u001b[0m\u001b[31m                                         [100%]\u001b[0m\n",
            "\n",
            "=========================== short test summary info ============================\n",
            "FAILED test_two.py::test_failing - assert (1, 2, 3) == (3, 2, 1)\n",
            "\u001b[31m============================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.01s\u001b[0m\u001b[31m ===============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specify function"
      ],
      "metadata": {
        "id": "GDIZFs_7xS0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest -v test_one.py::test_passing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paHqHdRFw7lp",
        "outputId": "d615cbe4-db1a-4f03-9e72-a4470313ea32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.7.13, pytest-7.1.2, pluggy-1.0.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /content\n",
            "plugins: typeguard-2.7.1\n",
            "\u001b[1mcollecting ... \u001b[0m\u001b[1m\rcollected 1 item                                                               \u001b[0m\n",
            "\n",
            "test_one.py::test_passing \u001b[32mPASSED\u001b[0m\u001b[32m                                         [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Discovery\n",
        "\n",
        "Given no arguments, pytest searches the current directory and all sub directories for test files.\n",
        "\n",
        "Naming conventions:\n",
        "* files: test_{NAME}.py or {NAME}_test.py\n",
        "* function: test_{NAME}.py\n",
        "* class: Test{NAME}.py"
      ],
      "metadata": {
        "id": "4L0L-k0dxarE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Outcomes:\n",
        "\n",
        "* PASSED (.) - test was successful\n",
        "* FAILED (F) - test was not succesful\n",
        "* SKIPPED (S) - test was skipped\n",
        "* XFAIL (x) - test failed as it was expected\n",
        "* XPASS (X) - test passed but was supposed to fail\n",
        "* ERROR (E) - error occured outside of the test function itself"
      ],
      "metadata": {
        "id": "AzB-f3wXycqW"
      }
    }
  ]
}